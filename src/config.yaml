# Metadata
solution:
  name: "Object Detection Solution"
  description: "A solution for object detection tasks."
  # docker_image: "supervisely/base-py-sdk:6.73.398"
  # instance_version: "6.13.8"
  # version: "1.0.0"

# Graph settings
settings:
  environment:
    variables:
      PROJECT_ID: "{{ $PROJECT_ID | default('null') }}"
  graph:
    height: "1800px"
    width: "100%"
    grid: true
  positions: &positions
    auto_import: &auto_import_position { x: 770, y: 30 }
    cloud_import: &cloud_import_position { x: 430, y: 30 }
    input_project: &input_project_position { x: 620, y: 150 }
    open_ai_clip: &open_ai_clip_position { x: 150, y: 206 }
    ai_index: &ai_index_position { x: 380, y: 206 }
    smart_sampling: &smart_sampling_position { x: 585, y: 380 }
    labeling_project: &labeling_project_position { x: 620, y: 500 }
    labeling_queue: &labeling_queue_position { x: 610, y: 730 }
    labeling_queue_performance:
      &labeling_queue_performance_position { x: 950, y: 729 }
    train_val_split: &train_val_split_position { x: 585, y: 1150 }
    move_labeled_data: &move_labeled_data_position { x: 585, y: 1270 }
    training_project: &training_project_position { x: 575, y: 1390 }
    training_project_stats: &training_project_stats_position { x: 950, y: 1389 }
  defaults: &defaults
    width: 250
    connection_settings: &defaults_connection_settings
      startSocket: "bottom"
      endSocket: "top"
      path: "grid"
      dash: false # {"len": 8, "gap": 8}
      color: "#B1B1B6"
      size: 1
      startPlug: "behind"
      endPlug: "arrow2"
      startPlugSize: 3
      endPlugSize: 3

# All nodes in the graph
nodes:
  # - id: "state_initialization"
  #   # placeholder for future state initialization node

  - id: "auto_import" # unique ID for the node
    name: "Manual D&D Import"
    description: "Each import creates a dataset folder in the Input Project, centralising all incoming data and easily managing it over time. Automatically detects 10+ annotation formats."
    type: "supervisely.solution.AutoImportNode" # type of the node to import
    parameters:
      project_id: "{{ $PROJECT_ID | default('null') }}"
      tooltip_position: "right"
      <<: *auto_import_position # x, y
    events:
      subscribe: [] # events to subscribe to
      publish: ["import_finished"] # events to publish after import is started

  - id: "cloud_import" # unique ID for the node
    name: "Import from Cloud"
    description: "Each import creates a dataset folder in the Input Project, centralising all incoming data and easily managing it over time. Automatically detects 10+ annotation formats."
    type: "supervisely.solution.CloudImportNode" # type of the node to import
    parameters:
      project_id: "{{ $PROJECT_ID | default('null') }}"
      <<: *cloud_import_position # x, y
    events:
      subscribe: ["import_started"] # events to subscribe to
      publish: ["import_started", "import_finished"] # events to subscribe to

    # # ?? define events that will be triggered after 'run' action
    # events:
    #   - topic: "import_finished"
    #     payload_schema:
    #       task_id:
    #         type: "integer"
    #         description: "ID of the import task"

    # # ?? define fields where import tasks will be stored in the state
    # state_fields:
    #   - tasks:
    #       type: "array"
    #       description: "List of import tasks"
    #       items:
    #         type: "object" # dict
    #         properties:
    #           task_id:
    #             type: "integer" # int
    #             description: "ID of the import task"
    #           status:
    #             type: "string" # str
    #             description: "Status of the import task"
    #           created_at:
    #             type: "string"
    #             format: "date-time"
    #             description: "Creation time of the import task"
    #           images_count:
    #             type: "integer"
    #             description: "Number of images in the import task"

  - id: "input_project"
    name: &input_project_name "Input Project"
    description: &input_project_description "The Input Project is the central hub for all incoming data. Data in this project will not be modified."
    type: "supervisely.solution.ProjectNode"
    parameters:
      title: *input_project_name
      description: *input_project_description
      project_id: "{{ $PROJECT_ID | default('null') }}"
      tooltip_position: "right"
      <<: *input_project_position # x, y
    source:
      - id: "cloud_import"
        connection_settings:
          <<: *defaults_connection_settings
      - id: "auto_import"
        connection_settings:
          <<: *defaults_connection_settings
      - id: "ai_index"
        connection_settings:
          <<: *defaults_connection_settings
          startSocket: "right"
          endSocket: "left"
          dash: { "len": 8, "gap": 8 }
          endPlug: "behind"
    events:
      subscribe: ["import_finished"] # events to subscribe to
      publish: [] # events to publish after import is finished

  - id: "open_ai_clip"
    name: &open_ai_clip_name "OpenAI CLIP"
    description: &open_ai_clip_description "OpenAI CLIP is a powerful model that can be used to generate embeddings for images in your project. These embeddings can be used for various tasks, such as image similarity search, prompt-based image retrieval. In this application, it is used to create an index and search images based on text prompts or clusters."
    type: "supervisely.solution.OpenAIClipServiceNode"
    parameters:
      <<: *open_ai_clip_position # x, y

  - id: "ai_index"
    name: &ai_index_name "AI Index"
    description: &ai_index_description "AI Search Index is a powerful tool that allows you to search for images in your dataset using AI models. It provides a quick and efficient way to find similar images based on visual features. You can use it in Smart Sampling node to select images for labeling based on specified prompt."
    type: "supervisely.solution.AiIndexNode"
    parameters:
      <<: *ai_index_position # x, y
      project_id: "{{ $PROJECT_ID | default('null') }}"
    source:
      - id: "open_ai_clip"
        connection_settings:
          <<: *defaults_connection_settings
          startSocket: "right"
          endSocket: "left"
          dash: { "len": 8, "gap": 8 }
          endPlug: "behind"

  - id: "smart_sampling"
    name: "Smart Sampling"
    description: "Selects a data sample from the input project and copies it to the labeling project. Supports various sampling strategies: random, k-means clustering, diversity-based, or using embeddings precomputed by the “AI Index” node for smarter selection."
    type: "supervisely.solution.SmartSamplingNode"
    parameters:
      project_id: "{{ $PROJECT_ID | default('null') }}"
      dst_project: "{{ $LABELING_PROJECT_ID | default('null') }}"
      <<: *smart_sampling_position # x, y
    source:
      - id: "input_project"
        connection_settings:
          <<: *defaults_connection_settings
    events:
      subscribe: ["import_finished"] # events to subscribe to
      publish: ["sample_finished"] # events to publish after sample is finished

  - id: "labeling_project"
    name: &labeling_project_name "Labeling Project"
    description: &labeling_project_description "Project specifically for labeling data. All data in this project is in the labeling process. After labeling, data will be moved to the Training Project."
    type: "supervisely.solution.ProjectNode"
    parameters:
      title: *labeling_project_name
      description: *labeling_project_description
      project_id: "{{ $LABELING_PROJECT_ID | default('null') }}"
      <<: *labeling_project_position
    source:
      - id: "smart_sampling"
        connection_settings:
          <<: *defaults_connection_settings
    events:
      subscribe: ["sample_finished", "train_val_split_finished"] # events to subscribe to
      publish: [] # events to publish after sample is finished

  - id: "labeling_queue"
    name: "Labeling Queue"
    description: "Labeling Queue management. Labeling queue is a full annotation workflow where annotators pick the next available image from a shared queue. Once labeled, images are sent for review and quality check. Rejected images return to the same annotator."
    type: "supervisely.solution.LabelingQueueNode"
    parameters:
      <<: *labeling_queue_position
      queue_id: "{{ $LABELING_QUEUE_ID | default('null') }}"
      collection_id: "{{ $LABELING_COLLECTION_ID | default('null') }}"
    source:
      - id: "labeling_project"
        connection_settings:
          <<: *defaults_connection_settings
      - id: "labeling_queue_performance"
        connection_settings:
          <<: *defaults_connection_settings
          startSocket: "left"
          endSocket: "right"
          dash: { "len": 8, "gap": 8 }
          startPlug: "disc"
          pointAnchor: { "x": "100%", "y": 29 }
    events:
      subscribe: ["sample_finished"] # events to subscribe to
      publish: ["images_to_move"] # events to publish after move labeled data is

  - id: "labeling_queue_performance"
    name: &labeling_queue_performance_title "Labeling Performance"
    description: &labeling_queue_performance_description "Labeling Queue performance metrics. This node tracks the performance of labeling jobs in the Labeling Queue. It provides real-time statistics on the number of images being labeled, reviewed, and approved."
    type: "supervisely.solution.LabelingQueuePerformanceNode"
    parameters:
      <<: *labeling_queue_performance_position
      title: *labeling_queue_performance_title
      description: *labeling_queue_performance_description
      queue_id: "{{ $LABELING_QUEUE_ID | default('null') }}"
    events:
      subscribe: []
      publish: []

  - id: "train_val_split"
    name: "Train/Val Split"
    description: "Split dataset into Train and Validation sets for model training. Datasets structure mirrors the Input Project with splits organized in corresponding Collections (e.g., 'train_1', 'val_1', etc.)."
    type: "supervisely.solution.TrainValSplitNode"
    parameters:
      dst_project_id: "{{ $TRAINING_PROJECT_ID | default('null') }}"
      <<: *train_val_split_position
    source:
      - id: "labeling_queue"
        connection_settings:
          <<: *defaults_connection_settings
    events:
      subscribe: ["images_to_move", "move_labeled_data_finished"] # events to subscribe to
      publish: ["train_val_split_finished"] # events to publish after train/val split is finished

  - id: "move_labeled_data"
    name: "Move Labeled Data"
    description: "Move labeled and accepted images to the Training Project."
    type: "supervisely.solution.MoveLabeledNode"
    parameters:
      src_project_id: "{{ $LABELING_PROJECT_ID | default('null') }}"
      dst_project_id: "{{ $TRAINING_PROJECT_ID | default('null') }}"
      <<: *move_labeled_data_position
    source:
      - id: "train_val_split"
        connection_settings:
          <<: *defaults_connection_settings
    events:
      subscribe: ["images_to_move"] # events to subscribe to
      publish: ["move_labeled_data_finished"] # events to publish after move labeled data is

  - id: "training_project"
    name: &training_project_name "Training Project"
    description: &training_project_description "Project specifically for training data. All data in this project is in the training process. After training, data will be moved to the Training Project."
    type: "supervisely.solution.ProjectNode"
    parameters:
      is_training: true
      title: *training_project_name
      description: *training_project_description
      project_id: "{{ $TRAINING_PROJECT_ID | default('null') }}"
      <<: *training_project_position
    source:
      - id: "move_labeled_data"
        connection_settings:
          <<: *defaults_connection_settings
      - id: "training_project_stats"
        connection_settings:
          <<: *defaults_connection_settings
          startSocket: "left"
          endSocket: "right"
          dash: { "len": 8, "gap": 8 }
          startPlug: "disc"
          pointAnchor: { "x": "100%", "y": 29 }
    events:
      subscribe: ["train_val_split_finished"] # events to subscribe to
      publish: [] # events to publish after move labeled data is finished

  - id: "training_project_stats"
    name: &training_project_stats_name "QA & Stats"
    description: &training_project_stats_description "Open the QA & Stats page to explore detailed insights into the training project.."
    type: "supervisely.solution.LinkNode"
    parameters:
      title: *training_project_stats_name
      description: *training_project_stats_description
      <<: *training_project_stats_position
      icon: "zmdi zmdi-chart"
      link: "/projects/{{ $TRAINING_PROJECT_ID | default('null') }}/stats/datasets"
      tooltip_position: "right"
    events:
      subscribe: []
      publish: []
